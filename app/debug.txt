$ python -m run_app.demo -e LDPC -t -v -p NoPlot
2019-03-15 19:32:10.332668: I C:\tf_jenkins\workspace\rel-win\M\windows\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
2019-03-15 19:32:10.397224: W C:\tf_jenkins\workspace\rel-win\M\windows\PY\36\tensorflow\core\framework\op_kernel.cc:1198] Data loss: Checksum does not match: stored 270613411 vs. calculated on the restored bytes 2182348907
2019-03-15 19:32:10.397996: W C:\tf_jenkins\workspace\rel-win\M\windows\PY\36\tensorflow\core\framework\op_kernel.cc:1198] Data loss: Checksum does not match: stored 2415026525 vs. calculated on the restored bytes 3532105713
2019-03-15 19:32:10.397532: W C:\tf_jenkins\workspace\rel-win\M\windows\PY\36\tensorflow\core\framework\op_kernel.cc:1198] Data loss: Checksum does not match: stored 961506730 vs. calculated on the restored bytes 134943937
2019-03-15 19:32:10.398074: W C:\tf_jenkins\workspace\rel-win\M\windows\PY\36\tensorflow\core\framework\op_kernel.cc:1198] Data loss: Checksum does not match: stored 2613886470 vs. calculated on the restored bytes 1018737959
2019-03-15 19:32:10.398025: W C:\tf_jenkins\workspace\rel-win\M\windows\PY\36\tensorflow\core\framework\op_kernel.cc:1198] Data loss: Checksum does not match: stored 4056808305 vs. calculated on the restored bytes 2382692005
2019-03-15 19:32:10.399967: W C:\tf_jenkins\workspace\rel-win\M\windows\PY\36\tensorflow\core\framework\op_kernel.cc:1198] Data loss: Checksum does not match: stored 1940785039 vs. calculated on the restored bytes 3617329387
2019-03-15 19:32:10.400067: W C:\tf_jenkins\workspace\rel-win\M\windows\PY\36\tensorflow\core\framework\op_kernel.cc:1198] Data loss: Checksum does not match: stored 877554505 vs. calculated on the restored bytes 728811412
2019-03-15 19:32:10.404614: W C:\tf_jenkins\workspace\rel-win\M\windows\PY\36\tensorflow\core\framework\op_kernel.cc:1198] Data loss: Checksum does not match: stored 1207165710 vs. calculated on the restored bytes 1441797604
2646
Size of outclipped:  Tensor("Output_Layer:0", shape=(?, 8), dtype=float32)
x_train_len:529200
y_train_len:1008
total_batch:3
self_batch_size:200
self_freq:20
n_features:4800
n_classes:8
len_original_waveform:1008
original_bin_str:100000100001011000011000110110110111101011011110001111100111011001101011101100101100100110110111010101111000000110011111000001110011011010100110111001110101111110001110011011100001010000100000011000110011110010111010001011000110111110001110001001010010101110110101011001111000101100011100101100000101011011010001010001001011011100111010110001101101010101000011100010001001001100110010010101111001100111000101110110001110010111001101000101011101111010011101011110111101101101010111110001101011111010111111011001011110111011000110011110010101000111111010100110110011110010110110111111001100110101010111000111011101111101101001111010111100000111110010111101101111001010110111110100010100011010101100001101111011101101001110100110010111111111001111111100010110100110100010100101101011101010011011001111011000101100110011100111010011001110101101110100001110000110110010011111110010100111111110111001101000011101100011010011000001011111110011111010101011010110110011101111100010010111001001001010101011110001100000
Epoch: 1 cost = 15.619
Epoch: 2 cost = 12.331
Epoch: 3 cost = 9.734
Epoch: 4 cost = 8.014
Epoch: 5 cost = 6.677
Epoch: 6 cost = 5.596
Epoch: 7 cost = 4.680
Epoch: 8 cost = 3.930
Epoch: 9 cost = 3.355
Epoch: 10 cost = 2.977
Epoch: 11 cost = 2.676
Epoch: 12 cost = 2.462
Epoch: 13 cost = 2.305
Epoch: 14 cost = 2.178
Epoch: 15 cost = 2.074
Epoch: 16 cost = 1.987
Epoch: 17 cost = 1.914
Epoch: 18 cost = 1.852
Epoch: 19 cost = 1.798
Epoch: 20 cost = 1.751
Epoch: 21 cost = 1.710
Epoch: 22 cost = 1.672
Epoch: 23 cost = 1.638
Epoch: 24 cost = 1.608
Epoch: 25 cost = 1.579
Epoch: 26 cost = 1.553
Epoch: 27 cost = 1.528
Epoch: 28 cost = 1.505
Epoch: 29 cost = 1.484
Epoch: 30 cost = 1.463
Epoch: 31 cost = 1.444
Epoch: 32 cost = 1.425
Epoch: 33 cost = 1.407
Epoch: 34 cost = 1.390
Epoch: 35 cost = 1.374
Epoch: 36 cost = 1.358
Epoch: 37 cost = 1.343
Epoch: 38 cost = 1.328
Epoch: 39 cost = 1.314
Epoch: 40 cost = 1.300
Epoch: 41 cost = 1.287
Epoch: 42 cost = 1.274
Epoch: 43 cost = 1.261
Epoch: 44 cost = 1.248
Epoch: 45 cost = 1.236
Epoch: 46 cost = 1.225
Epoch: 47 cost = 1.213
Epoch: 48 cost = 1.202
Epoch: 49 cost = 1.190
Epoch: 50 cost = 1.180
2604
Size of outclipped:  Tensor("Output_Layer_1:0", shape=(?, 8), dtype=float32)
x_train_len:520800
y_train_len:992
total_batch:3
self_batch_size:200
self_freq:20
n_features:4800
n_classes:8
len_original_waveform:992
original_bin_str:11111011001001110000100000111010100101010001110010110010010111101000101110001110010110101101000111011010111110000011001111011000100010010011001111101101111111100110010111111001111111111010010001111000111110001111011101101011111011010000110110111000011000111010101111101111000100110100001100111111010011011001010110111111101000110001111010011111110010011110010011101010110101000101110001110001001010111000001110111111001001010101111010101011110001001100001000101110110111000011100101100111101101011001111100010000010000001100111111010100000100010110000111100110100110001001011100100000010110111011110111011111001001010101100001110110111001110110111001011100010100100011011010111111011000110011111111111001011000101010101110011111111111110110110001110001000001100111011101011011001110011100101100110110000011000101011111000100101110010111010111111011011101110111001110101110111001010101111000111001111000101110001100110010011101010001100010010001001100111010101100011100010111111010011110001010
Epoch: 1 cost = 15.802
Epoch: 2 cost = 13.662
Epoch: 3 cost = 11.226
Epoch: 4 cost = 9.492
Epoch: 5 cost = 8.297
Epoch: 6 cost = 7.426
Epoch: 7 cost = 6.848
Epoch: 8 cost = 6.360
Epoch: 9 cost = 5.931
Epoch: 10 cost = 5.551
Epoch: 11 cost = 5.203
Epoch: 12 cost = 4.871
Epoch: 13 cost = 4.603
Epoch: 14 cost = 4.428
Epoch: 15 cost = 4.292
Epoch: 16 cost = 4.062
Epoch: 17 cost = 3.914
Epoch: 18 cost = 3.785
Epoch: 19 cost = 3.661
Epoch: 20 cost = 3.529
Epoch: 21 cost = 3.414
Epoch: 22 cost = 3.320
Epoch: 23 cost = 3.229
Epoch: 24 cost = 3.139
Epoch: 25 cost = 3.046
Epoch: 26 cost = 2.960
Epoch: 27 cost = 2.885
Epoch: 28 cost = 2.814
Epoch: 29 cost = 2.745
Epoch: 30 cost = 2.678
Epoch: 31 cost = 2.612
Epoch: 32 cost = 2.547
Epoch: 33 cost = 2.484
Epoch: 34 cost = 2.424
Epoch: 35 cost = 2.368
Epoch: 36 cost = 2.313
Epoch: 37 cost = 2.261
Epoch: 38 cost = 2.211
Epoch: 39 cost = 2.164
Epoch: 40 cost = 2.120
Epoch: 41 cost = 2.078
Epoch: 42 cost = 2.039
Epoch: 43 cost = 2.002
Epoch: 44 cost = 1.966
Epoch: 45 cost = 1.932
Epoch: 46 cost = 1.899
Epoch: 47 cost = 1.868
Epoch: 48 cost = 1.837
Epoch: 49 cost = 1.807
Epoch: 50 cost = 1.778
2646
Size of outclipped:  Tensor("Output_Layer_2:0", shape=(?, 8), dtype=float32)
x_train_len:529200
y_train_len:1008
total_batch:3
self_batch_size:200
self_freq:20
n_features:4800
n_classes:8
len_original_waveform:1008
original_bin_str:111111101111010011101000101000111000110100110011110101110111011110101111110000011001001001100101000100101110000111111001110111110101111101011110110110101111111100001100011111011011101111100111111110010111011010011001111110010011010101111010101100111110011101011000001101011100001010010011100011111010010101011100101010001101001000001000101110000011010111010001101010010011101111000111010010101111010000100000111000010111011011101011001010011101101101010100001011001111110010100111101010110000001100001101110101100011011011000000111010110101110110001011101100101110110111110111101000100111010110001000011101110111011101110010010101110010110000110110011000101100110011101111111001001111001000100111111000111100111101011001101101110010001101010001100010110101011000011100010111111101111111011011110100110101010011001101010111010100110111110110011001011101000011100011010101011101011111001100001010101110100011101011111010110110111010111110110011111101001000011100010011001011101100110011111001110010011111000000
Epoch: 1 cost = 8.564
Epoch: 2 cost = 7.019
Epoch: 3 cost = 6.067
Epoch: 4 cost = 5.368
Epoch: 5 cost = 4.801
Epoch: 6 cost = 4.316
Epoch: 7 cost = 3.904
Epoch: 8 cost = 3.554
Epoch: 9 cost = 3.248
Epoch: 10 cost = 2.970
Epoch: 11 cost = 2.713
Epoch: 12 cost = 2.462
Epoch: 13 cost = 2.242
Epoch: 14 cost = 2.091
Epoch: 15 cost = 1.964
Epoch: 16 cost = 1.833
Epoch: 17 cost = 1.679
Epoch: 18 cost = 1.623
Epoch: 19 cost = 1.577
Epoch: 20 cost = 1.536
Epoch: 21 cost = 1.498
Epoch: 22 cost = 1.462
Epoch: 23 cost = 1.430
Epoch: 24 cost = 1.399
Epoch: 25 cost = 1.371
Epoch: 26 cost = 1.344
Epoch: 27 cost = 1.319
Epoch: 28 cost = 1.296
Epoch: 29 cost = 1.274
Epoch: 30 cost = 1.253
Epoch: 31 cost = 1.234
Epoch: 32 cost = 1.215
Epoch: 33 cost = 1.197
Epoch: 34 cost = 1.179
Epoch: 35 cost = 1.163
Epoch: 36 cost = 1.147
Epoch: 37 cost = 1.132
Epoch: 38 cost = 1.117
Epoch: 39 cost = 1.103
Epoch: 40 cost = 1.089
Epoch: 41 cost = 1.076
Epoch: 42 cost = 1.063
Epoch: 43 cost = 1.051
Epoch: 44 cost = 1.039
Epoch: 45 cost = 1.027
Epoch: 46 cost = 1.015
Epoch: 47 cost = 1.004
Epoch: 48 cost = 0.994
Epoch: 49 cost = 0.983
Epoch: 50 cost = 0.973
2646
Size of outclipped:  Tensor("Output_Layer_3:0", shape=(?, 8), dtype=float32)
x_train_len:529200
y_train_len:1008
total_batch:3
self_batch_size:200
self_freq:20
n_features:4800
n_classes:8
len_original_waveform:1008
original_bin_str:100001101000010110110100111110101100101111000010000111110011111101111010110110111111011010101110100110011111001011001011101101101000111010110010111110100100011010101001010001101001101100101010101010111110111001000100111111010101010111100110010011001000000101101110101110101001110111100000011111110101101100001101101111110001111111000111111111110110100011011110101100101011001101110111000110101111011010000111111101110100100010101101111011011000111001111111100100011011011101110111000011010110100101101100110110101101010101001110011011111111110101110000110100101100101010111000011000010110000110000001101110101111010000011001111011001111010111110101001000111011110101011111000100000100100110110011101011111110011100001111110101110110111010001011110101010011010101110100010100111001100110001111101010011001110010101011111111011111001111100110101011000011111011110010101111111001010111101010101111100110011101001110000110101101001001110010111100011011001011111111100100101100110101111110100111001110101010100000
            var_name_list = [v.name for v in tf.trainable_variables()]
            try:
                print('MEMORY VAR NAMES:' + str(var_name_list))
                reader = pywrap_tensorflow.NewCheckpointReader('./tf.model')
                var_to_shape_map = reader.get_variable_to_shape_map()
                print(str('CHECKPOINT KEY NAMES:') + str(var_to_shape_map))
            except:

Epoch: 1 cost = 9.031
Epoch: 2 cost = 7.024
Epoch: 3 cost = 6.061
Epoch: 4 cost = 5.328
Epoch: 5 cost = 4.623
Epoch: 6 cost = 4.111
Epoch: 7 cost = 3.654
Epoch: 8 cost = 3.280
Epoch: 9 cost = 2.976
Epoch: 10 cost = 2.718
Epoch: 11 cost = 2.497
Epoch: 12 cost = 2.307
Epoch: 13 cost = 2.142
Epoch: 14 cost = 1.999
Epoch: 15 cost = 1.869
Epoch: 16 cost = 1.754
Epoch: 17 cost = 1.657
Epoch: 18 cost = 1.573
Epoch: 19 cost = 1.500
Epoch: 20 cost = 1.435
Epoch: 21 cost = 1.376
Epoch: 22 cost = 1.324
Epoch: 23 cost = 1.277
Epoch: 24 cost = 1.234
Epoch: 25 cost = 1.194
Epoch: 26 cost = 1.157
Epoch: 27 cost = 1.122
Epoch: 28 cost = 1.089
Epoch: 29 cost = 1.059
Epoch: 30 cost = 1.029
Epoch: 31 cost = 1.002
Epoch: 32 cost = 0.975
Epoch: 33 cost = 0.949
Epoch: 34 cost = 0.925
Epoch: 35 cost = 0.901
Epoch: 36 cost = 0.877
Epoch: 37 cost = 0.854
Epoch: 38 cost = 0.832
Epoch: 39 cost = 0.809
Epoch: 40 cost = 0.788
Epoch: 41 cost = 0.767
Epoch: 42 cost = 0.747
Epoch: 43 cost = 0.728
Epoch: 44 cost = 0.710
Epoch: 45 cost = 0.693
Epoch: 46 cost = 0.678
Epoch: 47 cost = 0.663
Epoch: 48 cost = 0.649
Epoch: 49 cost = 0.636
Epoch: 50 cost = 0.624
2625
Size of outclipped:  Tensor("Output_Layer_4:0", shape=(?, 8), dtype=float32)
x_train_len:525000
y_train_len:1000
total_batch:3
self_batch_size:200
self_freq:20
n_features:4800
n_classes:8
len_original_waveform:1000
original_bin_str:1101100110101110101010011111001101110010111001111101001011100110001010001011101010111010101100111000111111101011110100100110111011101111010001110111111010011011110001011010011111010110000101000010010001011100101001110110010011111001111100100010110011010001101001000010110101101101110010011101010101011010011111001100001010111001111011101001010001111111110011111010101000110101100110001110111101110101001110110011010011001110100100001011010001001111000011010111111000110101111111010100000011111011001101011101111110111001101110110011010111111010111101000101000111110110111111110111110011010000101011011001010110001001001101100101111110100111011110101011111010101101011011100000011111101100011101100110000011100101101001001011101010110000110011100110110101011010011010111001011100011110101100010110101111001111111101011101001100100101000111101110001101001111010111111010010011100111100110111110010011111111011111011110100001000001101110011101010000001101011110110110010111001010000111011011001100000000
Epoch: 1 cost = 10.619
Epoch: 2 cost = 7.946
Epoch: 3 cost = 6.619
Epoch: 4 cost = 5.747
Epoch: 5 cost = 5.114
Epoch: 6 cost = 4.644
Epoch: 7 cost = 4.282
Epoch: 8 cost = 3.991
Epoch: 9 cost = 3.746
Epoch: 10 cost = 3.524
Epoch: 11 cost = 3.293
Epoch: 12 cost = 3.081
Epoch: 13 cost = 2.922
Epoch: 14 cost = 2.786
Epoch: 15 cost = 2.666
Epoch: 16 cost = 2.558
Epoch: 17 cost = 2.459
Epoch: 18 cost = 2.366
Epoch: 19 cost = 2.277
Epoch: 20 cost = 2.193
Epoch: 21 cost = 2.112
Epoch: 22 cost = 2.035
Epoch: 23 cost = 1.962
Epoch: 24 cost = 1.894
Epoch: 25 cost = 1.832
Epoch: 26 cost = 1.777
Epoch: 27 cost = 1.727
Epoch: 28 cost = 1.681
Epoch: 29 cost = 1.640
Epoch: 30 cost = 1.601
Epoch: 31 cost = 1.566
Epoch: 32 cost = 1.533
Epoch: 33 cost = 1.502
Epoch: 34 cost = 1.474
Epoch: 35 cost = 1.447
Epoch: 36 cost = 1.422
Epoch: 37 cost = 1.398
Epoch: 38 cost = 1.376
Epoch: 39 cost = 1.355
Epoch: 40 cost = 1.335
Epoch: 41 cost = 1.315
Epoch: 42 cost = 1.297
Epoch: 43 cost = 1.280
Epoch: 44 cost = 1.263
Epoch: 45 cost = 1.247
Epoch: 46 cost = 1.231
Epoch: 47 cost = 1.216
Epoch: 48 cost = 1.202
Epoch: 49 cost = 1.188
Epoch: 50 cost = 1.174
2604
Size of outclipped:  Tensor("Output_Layer_5:0", shape=(?, 8), dtype=float32)
x_train_len:520800
y_train_len:992
total_batch:3
self_batch_size:200
self_freq:20
n_features:4800
n_classes:8
len_original_waveform:992
original_bin_str:10001011000111111100100110111110011110011011101001111101101011000001100101000111101100010001001011001100001101000110100111111001111100110001111110111000001000001100111110100011000010111011111000110111110000001000101101011011101101001111101010000101011000110111111001001011001101011101001110001110100110010110100001001100100010100100011100010000101100001100101111101101111010111101010001101011011010011111001111101110000110001111110101000011101011110101101000111101001010000111101111101011010101111001001010001110011010011000101101110111110011101111111011011010110001011101111000110100101110101001010100011111100110101110100011101010111110101101010011110001110011111100001101100111110110010011100001001011011111110111010100110100010110001011101100110111101010101010000010110111110000100101011100111101101110000101010100101111110001011101100010111111010101101101101111110101010100101111001110011110011111100001010001001111110001011000111010110110110011111110111100110000101000111110111110000000
Epoch: 1 cost = 8.144
Epoch: 2 cost = 5.622
Epoch: 3 cost = 4.591
Epoch: 4 cost = 3.908
Epoch: 5 cost = 3.395
Epoch: 6 cost = 3.060
Epoch: 7 cost = 2.825
Epoch: 8 cost = 2.614
Epoch: 9 cost = 2.437
Epoch: 10 cost = 2.303
Epoch: 11 cost = 2.190
Epoch: 12 cost = 2.093
Epoch: 13 cost = 2.008
Epoch: 14 cost = 1.934
Epoch: 15 cost = 1.868
Epoch: 16 cost = 1.809
Epoch: 17 cost = 1.756
Epoch: 18 cost = 1.708
Epoch: 19 cost = 1.664
Epoch: 20 cost = 1.624
Epoch: 21 cost = 1.586
Epoch: 22 cost = 1.551
Epoch: 23 cost = 1.518
Epoch: 24 cost = 1.487
Epoch: 25 cost = 1.458
Epoch: 26 cost = 1.431
Epoch: 27 cost = 1.405
Epoch: 28 cost = 1.380
Epoch: 29 cost = 1.357
Epoch: 30 cost = 1.335
Epoch: 31 cost = 1.313
Epoch: 32 cost = 1.292
Epoch: 33 cost = 1.271
Epoch: 34 cost = 1.251
Epoch: 35 cost = 1.232
Epoch: 36 cost = 1.212
Epoch: 37 cost = 1.193
Epoch: 38 cost = 1.172
Epoch: 39 cost = 1.153
Epoch: 40 cost = 1.134
Epoch: 41 cost = 1.117
Epoch: 42 cost = 1.102
Epoch: 43 cost = 1.088
Epoch: 44 cost = 1.074
Epoch: 45 cost = 1.061
Epoch: 46 cost = 1.048
Epoch: 47 cost = 1.035
Epoch: 48 cost = 1.024
Epoch: 49 cost = 1.012
Epoch: 50 cost = 1.001
2604
Size of outclipped:  Tensor("Output_Layer_6:0", shape=(?, 8), dtype=float32)
x_train_len:520800
y_train_len:992
total_batch:3
self_batch_size:200
self_freq:20
n_features:4800
n_classes:8
len_original_waveform:992
original_bin_str:10011001010000110100111011110111111101110000010010011000100111111011100011001110100110110111110001101100111001011100011101011100001111100110100111011101101011101100110110111101111001000101100100110101011010110110101110001001111110100000111101101001100111001111000101111101010111001010100111110011010110110011001101111100010010011011010100111100010101100101110100110110001111101010101011111010011101001110111101110110001001111001101101011100001100001110110101111101100111010100000010100011001011111011010011110110100000110001001011111110000110100100000111101111111001101011110001101110111000101101011110011001011111010100001101001111001010110111000101011101110011100010011010111101001110101010100001110001011000101010110000011011111010001101110111010111000101111000101000111101011010111110110000101111110101110110111111101011101101001100111110110100010110011000111110111001110110000101100110011111101010101101100000010110110011101001100110111110100101101101110011110001110100111101110100110000
Epoch: 1 cost = 7.860
Epoch: 2 cost = 6.716
Epoch: 3 cost = 6.333
Epoch: 4 cost = 6.014
Epoch: 5 cost = 5.726
Epoch: 6 cost = 5.453
Epoch: 7 cost = 5.185
Epoch: 8 cost = 4.900
Epoch: 9 cost = 4.527
Epoch: 10 cost = 4.090
Epoch: 11 cost = 3.780
Epoch: 12 cost = 3.532
Epoch: 13 cost = 3.344
Epoch: 14 cost = 3.199
Epoch: 15 cost = 3.081
Epoch: 16 cost = 2.982
Epoch: 17 cost = 2.896
Epoch: 18 cost = 2.818
Epoch: 19 cost = 2.748
Epoch: 20 cost = 2.685
Epoch: 21 cost = 2.626
Epoch: 22 cost = 2.573
Epoch: 23 cost = 2.524
Epoch: 24 cost = 2.478
Epoch: 25 cost = 2.436
Epoch: 26 cost = 2.396
Epoch: 27 cost = 2.358
Epoch: 28 cost = 2.322
Epoch: 29 cost = 2.288
Epoch: 30 cost = 2.256
Epoch: 31 cost = 2.225
Epoch: 32 cost = 2.196
Epoch: 33 cost = 2.167
Epoch: 34 cost = 2.140
Epoch: 35 cost = 2.114
Epoch: 36 cost = 2.088
Epoch: 37 cost = 2.064
Epoch: 38 cost =
